#!/usr/bin/env python3
"""
Automated Test Report Generator for ValuerPro AI Testing System
Generates comprehensive, professional test reports with AI insights
"""

import asyncio
import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import argparse
from dataclasses import dataclass, asdict
import base64
from io import BytesIO
import requests

# Template and formatting imports
from jinja2 import Template, Environment, FileSystemLoader
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from reportlab.graphics.shapes import Drawing
from reportlab.graphics.charts.lineplots import LinePlot
from reportlab.graphics.charts.barcharts import VerticalBarChart
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT

# Configure matplotlib for headless operation
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")


@dataclass
class ReportConfig:
    """Configuration for report generation"""
    title: str = "ValuerPro AI Testing System Report"
    subtitle: str = "Comprehensive Quality Assurance Analysis"
    company: str = "ValuerPro"
    report_type: str = "comprehensive"  # comprehensive, summary, executive
    time_period: str = "7_days"  # 1_day, 7_days, 30_days
    include_charts: bool = True
    include_ai_insights: bool = True
    include_recommendations: bool = True
    output_formats: List[str] = None
    output_directory: str = "reports"
    
    def __post_init__(self):
        if self.output_formats is None:
            self.output_formats = ["html", "pdf", "json"]


class AutomatedReportGenerator:
    """AI-powered automated test report generator"""
    
    def __init__(self, config: ReportConfig):
        self.config = config
        self.api_base_url = "http://localhost:8000/monitoring"
        self.report_data = {}
        self.charts = {}
        
        # Create output directory
        Path(self.config.output_directory).mkdir(exist_ok=True)
        
        # Initialize report styles
        self._setup_styles()
    
    def _setup_styles(self):
        """Setup styling for reports"""
        self.styles = getSampleStyleSheet()
        
        # Custom styles
        self.styles.add(ParagraphStyle(
            name='CustomTitle',
            parent=self.styles['Heading1'],
            fontSize=24,
            textColor=colors.HexColor('#1a1a2e'),
            alignment=TA_CENTER,
            spaceAfter=30
        ))
        
        self.styles.add(ParagraphStyle(
            name='CustomSubtitle',
            parent=self.styles['Heading2'],
            fontSize=16,
            textColor=colors.HexColor('#666'),
            alignment=TA_CENTER,
            spaceAfter=20
        ))
        
        self.styles.add(ParagraphStyle(
            name='SectionHeader',
            parent=self.styles['Heading2'],
            fontSize=14,
            textColor=colors.HexColor('#2c5aa0'),
            spaceBefore=20,
            spaceAfter=10
        ))
        
        self.styles.add(ParagraphStyle(
            name='InsightBox',
            parent=self.styles['Normal'],
            fontSize=10,
            textColor=colors.HexColor('#2c5aa0'),
            leftIndent=20,
            rightIndent=20,
            borderWidth=1,
            borderColor=colors.HexColor('#e0e0e0'),
            backColor=colors.HexColor('#f8f9fa')
        ))
    
    async def generate_report(self) -> Dict[str, str]:
        """Generate comprehensive test report"""
        print(f"üîÑ Generating {self.config.report_type} report for {self.config.time_period}...")
        
        try:
            # Collect data from monitoring APIs
            await self._collect_report_data()
            
            # Generate visualizations
            if self.config.include_charts:
                await self._generate_charts()
            
            # Generate reports in requested formats
            output_files = {}
            
            if "html" in self.config.output_formats:
                html_file = await self._generate_html_report()
                output_files["html"] = html_file
                print(f"‚úÖ HTML report: {html_file}")
            
            if "pdf" in self.config.output_formats:
                pdf_file = await self._generate_pdf_report()
                output_files["pdf"] = pdf_file
                print(f"‚úÖ PDF report: {pdf_file}")
            
            if "json" in self.config.output_formats:
                json_file = await self._generate_json_report()
                output_files["json"] = json_file
                print(f"‚úÖ JSON report: {json_file}")
            
            print(f"üéâ Report generation completed successfully!")
            return output_files
            
        except Exception as e:
            print(f"‚ùå Error generating report: {e}")
            raise
    
    async def _collect_report_data(self):
        """Collect data from monitoring APIs"""
        print("üìä Collecting test data...")
        
        try:
            # System health data
            response = requests.get(f"{self.api_base_url}/dashboard", timeout=10)
            if response.status_code == 200:
                self.report_data["dashboard"] = response.json()
            
            # AI insights
            response = requests.get(f"{self.api_base_url}/ai-insights", timeout=10)
            if response.status_code == 200:
                self.report_data["ai_insights"] = response.json()
            
            # Test results
            response = requests.get(f"{self.api_base_url}/test-results", timeout=10)
            if response.status_code == 200:
                self.report_data["test_results"] = response.json()
            
            # Live metrics
            response = requests.get(f"{self.api_base_url}/live-metrics", timeout=10)
            if response.status_code == 200:
                self.report_data["live_metrics"] = response.json()
            
            print(f"‚úÖ Collected data from {len(self.report_data)} endpoints")
            
        except requests.exceptions.RequestException as e:
            print(f"‚ö†Ô∏è API connection issue: {e}")
            # Use sample data for demonstration
            await self._generate_sample_data()
        except Exception as e:
            print(f"‚ùå Error collecting data: {e}")
            await self._generate_sample_data()
    
    async def _generate_sample_data(self):
        """Generate sample data for demonstration"""
        print("üìã Using sample data for demonstration...")
        
        self.report_data = {
            "dashboard": {
                "current_health": {
                    "timestamp": datetime.now().isoformat(),
                    "overall_score": 92.5,
                    "test_pass_rate": 94.2,
                    "performance_score": 88.7,
                    "security_score": 95.1,
                    "accessibility_score": 91.3,
                    "active_services": ["backend", "frontend", "database"],
                    "failed_services": []
                },
                "metrics_summary": {
                    "total_tests": 42,
                    "passed_tests": 40,
                    "pass_rate": 95.2,
                    "avg_execution_time": 1.2
                }
            },
            "ai_insights": {
                "test_prioritization": {
                    "highest_priority": "valuation_calc",
                    "priority_score": 25.0,
                    "reason": "Core business logic with financial impact"
                },
                "behavior_prediction": {
                    "scenarios_generated": 3,
                    "highest_risk": "session_expiry_during_work",
                    "risk_probability": 0.6
                },
                "failure_prediction": {
                    "patterns_detected": 1,
                    "component_focus": "auth",
                    "recommendation": "Focus debugging efforts on auth component"
                }
            },
            "test_results": {
                "execution_summary": {
                    "timestamp": datetime.now().isoformat(),
                    "total_tests": 42,
                    "passed": 40,
                    "failed": 1,
                    "skipped": 1,
                    "pass_rate": 95.2,
                    "execution_time": "2.3s"
                }
            },
            "live_metrics": {
                "timestamp": datetime.now().isoformat(),
                "quality_scores": {
                    "overall_quality": 92.5,
                    "test_coverage": 89.3,
                    "performance": 91.2,
                    "security": 95.1,
                    "accessibility": 87.9
                }
            }
        }
    
    async def _generate_charts(self):
        """Generate charts and visualizations"""
        print("üìà Generating charts...")
        
        try:
            # Quality scores chart
            await self._create_quality_scores_chart()
            
            # Trends chart
            await self._create_trends_chart()
            
            # Test execution chart
            await self._create_test_execution_chart()
            
            print(f"‚úÖ Generated {len(self.charts)} charts")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Chart generation error: {e}")
    
    async def _create_quality_scores_chart(self):
        """Create quality scores radar chart"""
        fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(projection='polar'))
        
        # Sample data
        categories = ['Overall', 'Coverage', 'Performance', 'Security', 'Accessibility']
        values = [92.5, 89.3, 91.2, 95.1, 87.9]
        
        # Add first value to end to close the circle
        values += values[:1]
        
        # Calculate angles
        angles = [n / float(len(categories)) * 2 * 3.14159 for n in range(len(categories))]
        angles += angles[:1]
        
        # Plot
        ax.plot(angles, values, 'o-', linewidth=2, label='Current Scores', color='#2c5aa0')
        ax.fill(angles, values, alpha=0.25, color='#2c5aa0')
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories)
        ax.set_ylim(0, 100)
        ax.set_title('Quality Scores Overview', size=16, y=1.08)
        ax.grid(True)
        
        plt.tight_layout()
        chart_path = Path(self.config.output_directory) / "quality_scores.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.charts["quality_scores"] = str(chart_path)
    
    async def _create_trends_chart(self):
        """Create trends chart"""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Sample trend data
        dates = [datetime.now() - timedelta(days=x) for x in range(7, 0, -1)]
        pass_rates = [94, 92, 95, 93, 96, 94, 95]
        performance_scores = [88, 90, 87, 91, 89, 92, 91]
        
        ax.plot(dates, pass_rates, marker='o', label='Pass Rate %', color='#2c5aa0', linewidth=2)
        ax.plot(dates, performance_scores, marker='s', label='Performance Score', color='#28a745', linewidth=2)
        
        ax.set_xlabel('Date')
        ax.set_ylabel('Score (%)')
        ax.set_title('Quality Trends (Last 7 Days)', fontsize=16)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Format x-axis
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
        plt.xticks(rotation=45)
        
        plt.tight_layout()
        chart_path = Path(self.config.output_directory) / "trends.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.charts["trends"] = str(chart_path)
    
    async def _create_test_execution_chart(self):
        """Create test execution distribution chart"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # Test status distribution
        labels = ['Passed', 'Failed', 'Skipped']
        sizes = [40, 1, 1]
        colors = ['#28a745', '#dc3545', '#ffc107']
        explode = (0.05, 0.05, 0.05)
        
        ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',
                shadow=True, startangle=90)
        ax1.set_title('Test Execution Results')
        
        # Test suite performance
        suites = ['Auth Tests', 'Validation', 'Integration', 'Performance', 'Security']
        durations = [1.2, 2.8, 3.5, 8.2, 1.9]
        
        bars = ax2.bar(suites, durations, color='#2c5aa0', alpha=0.7)
        ax2.set_ylabel('Duration (seconds)')
        ax2.set_title('Test Suite Performance')
        ax2.tick_params(axis='x', rotation=45)
        
        # Add value labels on bars
        for bar in bars:
            height = bar.get_height()
            ax2.annotate(f'{height}s',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 3),  # 3 points vertical offset
                        textcoords="offset points",
                        ha='center', va='bottom')
        
        plt.tight_layout()
        chart_path = Path(self.config.output_directory) / "test_execution.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.charts["test_execution"] = str(chart_path)
    
    async def _generate_html_report(self) -> str:
        """Generate HTML report"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"valuerpro_test_report_{timestamp}.html"
        filepath = Path(self.config.output_directory) / filename
        
        # HTML template
        html_template = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ config.title }}</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 2rem;
        }
        .header h1 {
            margin: 0;
            font-size: 2.5rem;
        }
        .header p {
            margin: 0.5rem 0 0 0;
            opacity: 0.9;
        }
        .summary-cards {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1rem;
            margin-bottom: 2rem;
        }
        .card {
            background: white;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            border-left: 4px solid #667eea;
        }
        .card h3 {
            margin: 0 0 1rem 0;
            color: #667eea;
        }
        .card .value {
            font-size: 2rem;
            font-weight: bold;
            color: #2c3e50;
        }
        .section {
            background: white;
            margin: 2rem 0;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .section h2 {
            color: #667eea;
            border-bottom: 2px solid #e9ecef;
            padding-bottom: 0.5rem;
        }
        .chart-container {
            text-align: center;
            margin: 1rem 0;
        }
        .chart-container img {
            max-width: 100%;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .insights-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1rem;
        }
        .insight-card {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 1rem;
            border-left: 4px solid #28a745;
        }
        .insight-card.warning {
            border-left-color: #ffc107;
        }
        .insight-card.error {
            border-left-color: #dc3545;
        }
        .insight-card h4 {
            margin: 0 0 0.5rem 0;
            color: #2c3e50;
        }
        .recommendations {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            border-radius: 10px;
            margin-top: 2rem;
        }
        .recommendations h3 {
            margin: 0 0 1rem 0;
        }
        .recommendations ul {
            margin: 0;
            padding-left: 1.5rem;
        }
        .recommendations li {
            margin-bottom: 0.5rem;
        }
        .footer {
            text-align: center;
            color: #6c757d;
            margin-top: 2rem;
            padding-top: 2rem;
            border-top: 1px solid #e9ecef;
        }
        .status-good { color: #28a745; }
        .status-warning { color: #ffc107; }
        .status-error { color: #dc3545; }
    </style>
</head>
<body>
    <div class="header">
        <h1>{{ config.title }}</h1>
        <p>{{ config.subtitle }}</p>
        <p>Generated on {{ timestamp }}</p>
    </div>
    
    <div class="summary-cards">
        <div class="card">
            <h3>Overall Quality Score</h3>
            <div class="value status-good">{{ data.dashboard.current_health.overall_score }}%</div>
        </div>
        <div class="card">
            <h3>Test Pass Rate</h3>
            <div class="value status-good">{{ data.dashboard.current_health.test_pass_rate }}%</div>
        </div>
        <div class="card">
            <h3>Performance Score</h3>
            <div class="value status-good">{{ data.dashboard.current_health.performance_score }}%</div>
        </div>
        <div class="card">
            <h3>Security Score</h3>
            <div class="value status-good">{{ data.dashboard.current_health.security_score }}%</div>
        </div>
    </div>
    
    {% if charts %}
    <div class="section">
        <h2>üìä Visual Analytics</h2>
        {% if charts.quality_scores %}
        <div class="chart-container">
            <h3>Quality Scores Overview</h3>
            <img src="data:image/png;base64,{{ charts.quality_scores_b64 }}" alt="Quality Scores Chart">
        </div>
        {% endif %}
        
        {% if charts.trends %}
        <div class="chart-container">
            <h3>Quality Trends</h3>
            <img src="data:image/png;base64,{{ charts.trends_b64 }}" alt="Trends Chart">
        </div>
        {% endif %}
        
        {% if charts.test_execution %}
        <div class="chart-container">
            <h3>Test Execution Analysis</h3>
            <img src="data:image/png;base64,{{ charts.test_execution_b64 }}" alt="Test Execution Chart">
        </div>
        {% endif %}
    </div>
    {% endif %}
    
    <div class="section">
        <h2>ü§ñ AI-Powered Insights</h2>
        <div class="insights-grid">
            <div class="insight-card">
                <h4>Test Prioritization</h4>
                <p><strong>Highest Priority:</strong> {{ data.ai_insights.test_prioritization.highest_priority }}</p>
                <p><strong>Score:</strong> {{ data.ai_insights.test_prioritization.priority_score }}</p>
                <p>{{ data.ai_insights.test_prioritization.reason }}</p>
            </div>
            <div class="insight-card warning">
                <h4>Behavior Prediction</h4>
                <p><strong>Scenarios Generated:</strong> {{ data.ai_insights.behavior_prediction.scenarios_generated }}</p>
                <p><strong>Highest Risk:</strong> {{ data.ai_insights.behavior_prediction.highest_risk }}</p>
                <p><strong>Risk Probability:</strong> {{ (data.ai_insights.behavior_prediction.risk_probability * 100)|round(1) }}%</p>
            </div>
            <div class="insight-card">
                <h4>Failure Prediction</h4>
                <p><strong>Patterns Detected:</strong> {{ data.ai_insights.failure_prediction.patterns_detected }}</p>
                <p><strong>Focus Component:</strong> {{ data.ai_insights.failure_prediction.component_focus }}</p>
                <p>{{ data.ai_insights.failure_prediction.recommendation }}</p>
            </div>
        </div>
    </div>
    
    <div class="section">
        <h2>üìã Test Execution Summary</h2>
        <div class="summary-cards">
            <div class="card">
                <h3>Total Tests</h3>
                <div class="value">{{ data.test_results.execution_summary.total_tests }}</div>
            </div>
            <div class="card">
                <h3>Passed</h3>
                <div class="value status-good">{{ data.test_results.execution_summary.passed }}</div>
            </div>
            <div class="card">
                <h3>Failed</h3>
                <div class="value status-error">{{ data.test_results.execution_summary.failed }}</div>
            </div>
            <div class="card">
                <h3>Execution Time</h3>
                <div class="value">{{ data.test_results.execution_summary.execution_time }}</div>
            </div>
        </div>
    </div>
    
    <div class="recommendations">
        <h3>üéØ AI-Powered Recommendations</h3>
        <ul>
            <li>Continue focusing on {{ data.ai_insights.test_prioritization.highest_priority }} tests for maximum impact</li>
            <li>{{ data.ai_insights.failure_prediction.recommendation }}</li>
            <li>Monitor {{ data.ai_insights.behavior_prediction.highest_risk }} scenarios closely</li>
            <li>Maintain current quality practices to sustain {{ data.dashboard.current_health.overall_score }}% quality score</li>
        </ul>
    </div>
    
    <div class="footer">
        <p>Generated by ValuerPro AI Testing System | {{ timestamp }}</p>
        <p>This report was automatically generated using AI-powered analytics and insights.</p>
    </div>
</body>
</html>
        """
        
        # Convert charts to base64
        charts_b64 = {}
        if self.charts:
            for chart_name, chart_path in self.charts.items():
                try:
                    with open(chart_path, "rb") as img_file:
                        charts_b64[f"{chart_name}_b64"] = base64.b64encode(img_file.read()).decode()
                except Exception as e:
                    print(f"‚ö†Ô∏è Could not encode chart {chart_name}: {e}")
        
        # Render template
        template = Template(html_template)
        html_content = template.render(
            config=self.config,
            data=self.report_data,
            charts=self.charts,
            charts_b64=charts_b64,
            timestamp=datetime.now().strftime("%B %d, %Y at %I:%M %p")
        )
        
        # Save HTML file
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return str(filepath)
    
    async def _generate_pdf_report(self) -> str:
        """Generate PDF report using ReportLab"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"valuerpro_test_report_{timestamp}.pdf"
        filepath = Path(self.config.output_directory) / filename
        
        try:
            # Create PDF document
            doc = SimpleDocTemplate(str(filepath), pagesize=A4)
            elements = []
            
            # Title
            title = Paragraph(self.config.title, self.styles['CustomTitle'])
            elements.append(title)
            
            subtitle = Paragraph(self.config.subtitle, self.styles['CustomSubtitle'])
            elements.append(subtitle)
            
            timestamp_para = Paragraph(
                f"Generated on {datetime.now().strftime('%B %d, %Y at %I:%M %p')}",
                self.styles['Normal']
            )
            elements.append(timestamp_para)
            elements.append(Spacer(1, 20))
            
            # Executive Summary
            elements.append(Paragraph("Executive Summary", self.styles['SectionHeader']))
            
            health_data = self.report_data.get('dashboard', {}).get('current_health', {})
            summary_text = f"""
            The ValuerPro AI Testing System has achieved an overall quality score of 
            <b>{health_data.get('overall_score', 0):.1f}%</b> with a test pass rate of 
            <b>{health_data.get('test_pass_rate', 0):.1f}%</b>. The system demonstrates 
            strong performance across all quality dimensions with AI-powered insights 
            providing actionable recommendations for continuous improvement.
            """
            
            elements.append(Paragraph(summary_text, self.styles['Normal']))
            elements.append(Spacer(1, 20))
            
            # Quality Metrics Table
            elements.append(Paragraph("Quality Metrics", self.styles['SectionHeader']))
            
            quality_data = [
                ['Metric', 'Score', 'Status'],
                ['Overall Quality', f"{health_data.get('overall_score', 0):.1f}%", 'Excellent'],
                ['Test Pass Rate', f"{health_data.get('test_pass_rate', 0):.1f}%", 'Excellent'],
                ['Performance', f"{health_data.get('performance_score', 0):.1f}%", 'Good'],
                ['Security', f"{health_data.get('security_score', 0):.1f}%", 'Excellent'],
                ['Accessibility', f"{health_data.get('accessibility_score', 0):.1f}%", 'Good']
            ]
            
            quality_table = Table(quality_data, colWidths=[2*inch, 1.5*inch, 1.5*inch])
            quality_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#667eea')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 14),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            elements.append(quality_table)
            elements.append(Spacer(1, 20))
            
            # AI Insights
            elements.append(Paragraph("AI-Powered Insights", self.styles['SectionHeader']))
            
            ai_insights = self.report_data.get('ai_insights', {})
            insights_text = f"""
            <b>Test Prioritization:</b> AI analysis recommends focusing on 
            '{ai_insights.get('test_prioritization', {}).get('highest_priority', 'N/A')}' 
            tests with a priority score of {ai_insights.get('test_prioritization', {}).get('priority_score', 0)}.
            <br/><br/>
            <b>Risk Assessment:</b> Behavioral analysis identified 
            '{ai_insights.get('behavior_prediction', {}).get('highest_risk', 'N/A')}' 
            as the highest risk scenario with {ai_insights.get('behavior_prediction', {}).get('risk_probability', 0)*100:.1f}% probability.
            <br/><br/>
            <b>Failure Prediction:</b> {ai_insights.get('failure_prediction', {}).get('patterns_detected', 0)} 
            failure patterns detected. Recommendation: {ai_insights.get('failure_prediction', {}).get('recommendation', 'N/A')}.
            """
            
            elements.append(Paragraph(insights_text, self.styles['Normal']))
            elements.append(Spacer(1, 20))
            
            # Test Results Summary
            elements.append(Paragraph("Test Execution Summary", self.styles['SectionHeader']))
            
            test_results = self.report_data.get('test_results', {}).get('execution_summary', {})
            results_data = [
                ['Metric', 'Value'],
                ['Total Tests', str(test_results.get('total_tests', 0))],
                ['Passed', str(test_results.get('passed', 0))],
                ['Failed', str(test_results.get('failed', 0))],
                ['Skipped', str(test_results.get('skipped', 0))],
                ['Pass Rate', f"{test_results.get('pass_rate', 0):.1f}%"],
                ['Execution Time', test_results.get('execution_time', 'N/A')]
            ]
            
            results_table = Table(results_data, colWidths=[3*inch, 2*inch])
            results_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2c5aa0')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.white),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            elements.append(results_table)
            elements.append(Spacer(1, 20))
            
            # Recommendations
            elements.append(Paragraph("Recommendations", self.styles['SectionHeader']))
            
            recommendations = [
                "Continue focusing on high-priority test areas identified by AI analysis",
                "Address identified failure patterns in the authentication component", 
                "Monitor session expiry scenarios to prevent user experience issues",
                "Maintain current testing practices to sustain high quality scores",
                "Consider implementing additional AI-powered test optimizations"
            ]
            
            for i, rec in enumerate(recommendations, 1):
                elements.append(Paragraph(f"{i}. {rec}", self.styles['Normal']))
            
            elements.append(Spacer(1, 30))
            
            # Footer
            footer_text = f"""
            <i>This report was automatically generated by the ValuerPro AI Testing System 
            on {datetime.now().strftime('%B %d, %Y')}. All metrics and insights are 
            powered by machine learning algorithms and real-time data analysis.</i>
            """
            elements.append(Paragraph(footer_text, self.styles['Normal']))
            
            # Build PDF
            doc.build(elements)
            
            return str(filepath)
            
        except Exception as e:
            print(f"‚ö†Ô∏è PDF generation fallback: {e}")
            # Create simple text-based PDF as fallback
            return await self._generate_simple_pdf_report(filepath)
    
    async def _generate_simple_pdf_report(self, filepath: Path) -> str:
        """Generate simple PDF report as fallback"""
        doc = SimpleDocTemplate(str(filepath), pagesize=A4)
        elements = []
        styles = getSampleStyleSheet()
        
        # Simple content
        elements.append(Paragraph(self.config.title, styles['Title']))
        elements.append(Spacer(1, 20))
        
        content = f"""
        Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        System Status: Operational
        Overall Quality Score: {self.report_data.get('dashboard', {}).get('current_health', {}).get('overall_score', 'N/A')}%
        
        This is a simplified version of the full AI testing report.
        """
        
        elements.append(Paragraph(content.replace('\n', '<br/>'), styles['Normal']))
        
        doc.build(elements)
        return str(filepath)
    
    async def _generate_json_report(self) -> str:
        """Generate JSON report"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"valuerpro_test_report_{timestamp}.json"
        filepath = Path(self.config.output_directory) / filename
        
        report_json = {
            "report_metadata": {
                "title": self.config.title,
                "generated_at": datetime.now().isoformat(),
                "report_type": self.config.report_type,
                "time_period": self.config.time_period,
                "version": "1.0.0"
            },
            "data": self.report_data,
            "charts": {k: f"Generated: {v}" for k, v in self.charts.items()},
            "summary": {
                "overall_score": self.report_data.get('dashboard', {}).get('current_health', {}).get('overall_score'),
                "test_pass_rate": self.report_data.get('dashboard', {}).get('current_health', {}).get('test_pass_rate'),
                "total_tests": self.report_data.get('test_results', {}).get('execution_summary', {}).get('total_tests'),
                "ai_insights_count": len(self.report_data.get('ai_insights', {}))
            }
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report_json, f, indent=2, default=str)
        
        return str(filepath)


async def main():
    """Main function for command-line usage"""
    parser = argparse.ArgumentParser(description="ValuerPro Automated Test Report Generator")
    parser.add_argument("--type", choices=["comprehensive", "summary", "executive"], 
                       default="comprehensive", help="Report type")
    parser.add_argument("--period", choices=["1_day", "7_days", "30_days"], 
                       default="7_days", help="Time period")
    parser.add_argument("--formats", nargs="+", choices=["html", "pdf", "json"], 
                       default=["html", "pdf"], help="Output formats")
    parser.add_argument("--output", default="reports", help="Output directory")
    parser.add_argument("--no-charts", action="store_true", help="Skip chart generation")
    
    args = parser.parse_args()
    
    config = ReportConfig(
        report_type=args.type,
        time_period=args.period,
        output_formats=args.formats,
        output_directory=args.output,
        include_charts=not args.no_charts
    )
    
    generator = AutomatedReportGenerator(config)
    
    try:
        output_files = await generator.generate_report()
        
        print(f"\nüéâ Report generation completed!")
        print(f"üìÅ Output directory: {config.output_directory}")
        print(f"üìä Generated {len(output_files)} files:")
        
        for format_type, filepath in output_files.items():
            print(f"  ‚Ä¢ {format_type.upper()}: {filepath}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Report generation failed: {e}")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)